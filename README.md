# ðŸ§  Project: Transformers & RNN with wandb Tracking

This project explores and compares two primary architectures for NLP tasks:

- **RNN (SEQ2SEQ)**: To capture sequential dependencies in textual data.
- **Transformers**: To leverage complex contextual dependencies using multi-head attention mechanisms.

Experiment tracking is powered by **Weights & Biases (wandb)**, providing metrics visualization, hyperparameter history, and centralized performance tracking. The goal is to evaluate the ability of both approaches to solve a specific task while identifying their strengths and limitations.
